

<launch>
    <!-- <include file="$(find usb_cam)/launch/usb_cam.launch" />
    <include file="$(find spinnaker_camera_driver)/launch/camera.launch" />
    <include file="$(find cits_logger)/launch/cits.launch" /> -->
    <node name="republish1" type="republish" pkg="image_transport" output="screen" args="compressed in:=/camera/image_color _image_transport:=compressed raw out:=/axis_camera/image_color" />
    <node name="republish2" type="republish" pkg="image_transport" output="screen" args="compressed in:=/usb_cam/image_raw _image_transport:=compressed raw out:=/axis_camera/image_raw" />
    <!-- <node name="republish2" type="republish" pkg="image_transport" output="screen" args="compressed in:=/camera/image_color _image_transport:=compressed raw out:=/axis_camera/image_color" /> -->

    <node pkg="yolov7_ros" type="detect_ros.py" name="detect" output="screen"
    ns="yolov7">
        <!-- Download the official weights from the original repo -->
        <param name="weights_path" type="str"
        value="$(find yolov7_ros)/src/weights/241101.pt"/>
        <!-- Path to a class_labels.txt file containing your desired class labels. The i-th entry corresponds to the i-th class id. For example, in coco class label 0 corresponds to 'person'. Files for the coco and berkeley deep drive datasets are provided in the 'class_labels/' directory. If you leave it empty then no class labels are visualized.-->
        <param name="classes_path" type="str" value="$(find yolov7_ros)/src/class_labels/label_0911.txt" />
        <!-- topic name to subscribe to -->
        <param name="img_topic" type="str" value="/camera/image_color" />
        <!-- topic name for the detection output -->
        <param name="out_topic" type="str" value="yolov7_detect" />
        <!-- confidence threshold -->
        <param name="conf_thresh" type="double" value="0.7" />
        <!-- intersection over union threshold -->`
        <param name="iou_thresh" type="double" value="0.45" />
        <param name="visualize" type="bool" value="true" />
        <!-- queue size for publishing -->
        <param name="queue_size" type="int" value="1" />
        <!-- image size to which to resize each input image before feeding into the
        network (the final output is rescaled to the original image size) -->
        <param name="img_size" type="int" value="640" />
        <!-- flag whether to also publish image with the visualized detections -->
        <!-- 'cuda' or 'cpu' -->
        <param name="device" type="str" value="cuda" />
    </node>

   <node pkg="yolov7_ros" type="detect_ros.py" name="detect_traffic" output="screen" ns="yolov7">
        <param name="weights_path" type="str"
        value="$(find yolov7_ros)/src/weights/241101.pt"/>

        <param name="classes_path" type="str" value="$(find yolov7_ros)/src/class_labels/label_0911.txt" />

        <param name="img_topic" type="str" value="/usb_cam/image_raw" />

        <param name="out_topic" type="str" value="yolov7_detect_traffic" />

        <param name="conf_thresh" type="double" value="0.7" />

        <param name="iou_thresh" type="double" value="0.45" />
        <param name="visualize" type="bool" value="true" />

        <param name="queue_size" type="int" value="1" />

       <param name="img_size" type="int" value="640" />

        <param name="device" type="str" value="cuda" />
    </node>

    <node pkg="yolov7_ros" type="post_process.py" name="vision_post_process_check" output="screen">
        <param name="classes_path" type="str" value="$(find yolov7_ros)/src/class_labels/label_0911.txt" />
    </node>


     <node type="rviz" name="rviz" pkg="rviz" args="-d $(find yolov7_ros)/rviz/config_file.rviz" />
    <!-- <node pkg="yolov7_ros" type="lane_detection_final.py" name="lane_detect" output="screen">
    </node> -->
</launch>
